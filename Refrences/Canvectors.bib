@inproceedings{kovatchev-etal-2021-vectors,
	title = "Can vectors read minds better than experts? Comparing data augmentation strategies for the automated scoring of children{'}s mindreading ability",
	author = "Kovatchev, Venelin  and
  	Smith, Phillip  and
  	Lee, Mark  and
  	Devine, Rory",
	editor = "Zong, Chengqing  and
  	Xia, Fei  and
  	Li, Wenjie  and
  	Navigli, Roberto",
	booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
	month = aug,
	year = "2021",
	address = "Online",
	publisher = "Association for Computational Linguistics (ACL)",
	conference = “ACL”,
	url = "https://aclanthology.org/2021.acl-long.96.pdf",
	doi = "10.18653/v1/2021.acl-long.96",
	pages = "1196--1206",
	abstract = "In this paper we implement and compare 7 different data augmentation strategies for the task of automatic scoring of children{'}s ability to understand others{'} thoughts, feelings, and desires (or {``}mindreading{''}). We recruit in-domain experts to re-annotate augmented samples and determine to what extent each strategy preserves the original rating. We also carry out multiple experiments to measure how much each augmentation strategy improves the performance of automatic scoring systems. To determine the capabilities of automatic systems to generalize to unseen data, we create UK-MIND-20 - a new corpus of children{'}s performance on tests of mindreading, consisting of 10,320 question-answer pairs. We obtain a new state-of-the-art performance on the MIND-CA corpus, improving macro-F1-score by 6 points. Results indicate that both the number of training examples and the quality of the augmentation strategies affect the performance of the systems. The task-specific augmentations generally outperform task-agnostic augmentations. Automatic augmentations based on vectors (GloVe, FastText) perform the worst. We find that systems trained on MIND-CA generalize well to UK-MIND-20. We demonstrate that data augmentation strategies also improve the performance on unseen data.",
code base = "https://github.com/venelink/augment-acl21.git"
}
