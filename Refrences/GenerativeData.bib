@inproceedings{yang-etal-2020-generative,
	title = "Generative Data Augmentation for Commonsense Reasoning",
	author = "Yang, Yiben  and
  	Malaviya, Chaitanya  and
  	Fernandez, Jared  and
  	Swayamdipta, Swabha  and
  	Le Bras, Ronan  and
  	Wang, Ji-Ping  and
  	Bhagavatula, Chandra  and
  	Choi, Yejin  and
  	Downey, Doug",
	editor = "Cohn, Trevor  and
  	He, Yulan  and
  	Liu, Yang",
	booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
	month = nov,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics (ACL)",
	conference = “ACL”,
	url = "https://aclanthology.org/2020.findings-emnlp.90.pdf",
	doi = "10.18653/v1/2020.findings-emnlp.90",
	pages = "1008--1025",
	abstract = "Recent advances in commonsense reasoning depend on large-scale human-annotated training sets to achieve peak performance. However, manual curation of training sets is expensive and has been shown to introduce annotation artifacts that neural models can readily exploit and overfit to. We propose a novel generative data augmentation technique, G-DAUG{\^{}}C, that aims to achieve more accurate and robust learning in a low-resource setting. Our approach generates synthetic examples using pretrained language models and selects the most informative and diverse set of examples for data augmentation. On experiments with multiple commonsense reasoning benchmarks, G-DAUG{\^{}}C consistently outperforms existing data augmentation methods based on back-translation, establishing a new state-of-the-art on WinoGrande, CODAH, and CommonsenseQA, as well as enhances out-of-distribution generalization, proving to be robust against adversaries or perturbations. Our analysis demonstrates that G-DAUG{\^{}}C produces a diverse set of fluent training examples, and that its selection and training approaches are important for performance.",
code Base =
"https://github.com/yangyiben/G-DAUG-c-Generative-Data-Augmentation-for-Commonsense-Reasoning.git"
}
