{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import simplejson\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mr_proc_results(raw_results):\n",
    "  \n",
    "\n",
    "  # Removing the f1 score for a bit\n",
    "  pr_results = [[[acc_score, f1_score, round(sum(qf_s)/11,2),round(np.std(qf_s),2)],\n",
    "  #pr_results = [[[acc_score, round(sum(qf_s)/11,2),round(np.std(qf_s),2)],\n",
    "                 [acc_score_wp1, f1_score_wp1, round(sum(qf_s_wp1)/11,2),round(np.std(qf_s_wp1),2)]] \n",
    "                for ([acc_score, qa_s, aa_s], [f1_score, qf_s, af_s],\n",
    "                     [acc_score_wp1, qa_s_wp1, aa_s_wp1], [f1_score_wp1, qf_s_wp1, af_s_wp1]) \n",
    "                in raw_results]\n",
    "\n",
    "  # Throw the list in an np array\n",
    "  pr_arr = np.array(pr_results)\n",
    "\n",
    "\n",
    "\n",
    "  return(np.mean(pr_arr,axis=0).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config\n",
    "\n",
    "# Path to data \n",
    "folder_path = \"Results/Original/\"\n",
    "\n",
    "# List of results to process\n",
    "all_res = [\"tr\",\"tr_qa\",\"tr_set\",\"bl\",\"bl_qa\",\"bl_set\"]\n",
    "# Filename prefix for each result type\n",
    "res_fpath = [\"tr_a_\",\"tr_qa_\",\"tr_qa_\",\"bl_a_\",\"bl_qa_\",\"bl_qa_\"]\n",
    "\n",
    "# Base filenames = names of all augmentation strategies\n",
    "base_files = [\"orig\",\"plus\",\"dict\",\"phrase\",\"reord\",\"fasttext\",\"glove\",\"ppdb\",\"wordnet\"]\n",
    "# Set filenames = names of all combinations of data\n",
    "set_files = [\"ab_lq\",\"ab_hq\",\"all_lq\",\"all_hq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the different groups of results\n",
    "results = {}\n",
    "\n",
    "for res_type in all_res:\n",
    "    results[res_type] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "for r_type,r_path in zip(all_res,res_fpath):\n",
    "    # Base results\n",
    "    if r_type not in [\"tr_set\",\"bl_set\"]:\n",
    "        # Load  all relevant results, go through all possible augmentations\n",
    "        for cur_aug in base_files:\n",
    "            # Results for basic augmentation : FOLDER/prefix_AUGNAME.txt    \n",
    "            cur_fname = folder_path + r_path + cur_aug + \".txt\"\n",
    "            # Open and load the file\n",
    "            with open(cur_fname,\"r\") as inp:\n",
    "                results[r_type][cur_aug] = simplejson.load(inp)\n",
    "    # Set results\n",
    "    else:\n",
    "        # Load  all relevant results, go through all possible sets\n",
    "        for cur_aug in set_files:\n",
    "            # Results for set augmentation : FOLDER/prefix_SETNAME.txt    \n",
    "            cur_fname = folder_path + r_path + cur_aug + \".txt\"\n",
    "            # Open and load the file\n",
    "            with open(cur_fname,\"r\") as inp:\n",
    "                results[r_type][cur_aug] = simplejson.load(inp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the processed results dictionary\n",
    "proc_res_df = {}\n",
    "\n",
    "# Loop through all different models in results, including 'combined' if it exists\n",
    "for r_type in results:\n",
    "    if r_type == 'combined' and isinstance(results['combined'], list):\n",
    "        # Process 'combined' as a list directly without keys\n",
    "        proc_res_df[r_type] = pd.DataFrame(data=[mr_proc_results(result) for result in results['combined']])\n",
    "        \n",
    "        # Assign a unique index to each row in the combined DataFrame\n",
    "        proc_res_df[r_type].index = [f\"{r_type}_result_{i+1}\" for i in range(len(results['combined']))]\n",
    "    else:\n",
    "        # Process other entries in 'results' as dictionaries with nested keys\n",
    "        proc_res_df[r_type] = pd.DataFrame(data=[mr_proc_results(results[r_type][aug]) for aug in results[r_type].keys()])\n",
    "        \n",
    "        # Fix the index to include model type and augmentation name\n",
    "        proc_res_df[r_type].index = [r_type + \"_\" + aug for aug in results[r_type].keys()]\n",
    "\n",
    "    # Set consistent column names for all DataFrames\n",
    "    proc_res_df[r_type].columns = ['Acc', \"F1\", \"F1-Q\", \"F1-STD\", \"UK20-Acc\", \"UK20-F1\", \"UK20-F1-Q\", \"UK20-F1-STD\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Acc     F1   F1-Q  F1-STD  UK20-Acc  UK20-F1  UK20-F1-Q  UK20-F1-STD\n",
      "tr_orig      0.898  0.894  0.845   0.052     0.854    0.850      0.795        0.029\n",
      "tr_plus      0.898  0.898  0.863   0.045     0.857    0.853      0.802        0.030\n",
      "tr_dict      0.926  0.924  0.902   0.033     0.858    0.852      0.801        0.028\n",
      "tr_phrase    0.923  0.923  0.904   0.033     0.857    0.853      0.803        0.028\n",
      "tr_reord     0.925  0.925  0.905   0.033     0.857    0.855      0.805        0.029\n",
      "tr_fasttext  0.919  0.918  0.893   0.036     0.854    0.850      0.800        0.030\n",
      "tr_glove     0.917  0.917  0.892   0.036     0.853    0.850      0.799        0.027\n",
      "tr_ppdb      0.921  0.920  0.897   0.035     0.856    0.853      0.803        0.030\n",
      "tr_wordnet   0.919  0.920  0.896   0.035     0.853    0.851      0.800        0.029\n",
      "\n",
      "                  Acc     F1   F1-Q  F1-STD  UK20-Acc  UK20-F1  UK20-F1-Q  UK20-F1-STD\n",
      "tr_qa_orig      0.925  0.925  0.877   0.059     0.891    0.889      0.839        0.029\n",
      "tr_qa_plus      0.927  0.925  0.902   0.036     0.893    0.892      0.848        0.026\n",
      "tr_qa_dict      0.947  0.947  0.936   0.028     0.897    0.892      0.853        0.024\n",
      "tr_qa_phrase    0.946  0.946  0.930   0.031     0.897    0.893      0.854        0.024\n",
      "tr_qa_reord     0.948  0.947  0.933   0.025     0.897    0.891      0.852        0.022\n",
      "tr_qa_fasttext  0.941  0.942  0.924   0.030     0.891    0.890      0.851        0.023\n",
      "tr_qa_glove     0.942  0.942  0.925   0.028     0.895    0.891      0.849        0.021\n",
      "tr_qa_ppdb      0.947  0.946  0.929   0.030     0.894    0.893      0.851        0.022\n",
      "tr_qa_wordnet   0.947  0.947  0.932   0.033     0.899    0.894      0.853        0.023\n",
      "\n",
      "                 Acc     F1   F1-Q  F1-STD  UK20-Acc  UK20-F1  UK20-F1-Q  UK20-F1-STD\n",
      "tr_set_ab_lq   0.967  0.966  0.957   0.021     0.898    0.895      0.855        0.021\n",
      "tr_set_ab_hq   0.972  0.972  0.963   0.022     0.900    0.897      0.858        0.020\n",
      "tr_set_all_lq  0.978  0.978  0.973   0.015     0.899    0.895      0.857        0.021\n",
      "tr_set_all_hq  0.985  0.986  0.980   0.011     0.901    0.898      0.858        0.023\n",
      "\n",
      "               Acc     F1   F1-Q  F1-STD  UK20-Acc  UK20-F1  UK20-F1-Q  UK20-F1-STD\n",
      "bl_orig      0.816  0.813  0.738   0.061     0.778    0.773      0.705        0.037\n",
      "bl_plus      0.813  0.810  0.763   0.046     0.778    0.774      0.709        0.033\n",
      "bl_dict      0.835  0.835  0.795   0.047     0.779    0.775      0.713        0.028\n",
      "bl_phrase    0.837  0.838  0.800   0.037     0.780    0.776      0.715        0.027\n",
      "bl_reord     0.840  0.837  0.804   0.047     0.776    0.771      0.712        0.029\n",
      "bl_fasttext  0.826  0.822  0.781   0.045     0.780    0.773      0.714        0.028\n",
      "bl_glove     0.823  0.821  0.779   0.045     0.772    0.765      0.706        0.030\n",
      "bl_ppdb      0.828  0.825  0.786   0.045     0.779    0.772      0.711        0.028\n",
      "bl_wordnet   0.831  0.827  0.789   0.046     0.777    0.770      0.708        0.027\n",
      "\n",
      "                  Acc     F1   F1-Q  F1-STD  UK20-Acc  UK20-F1  UK20-F1-Q  UK20-F1-STD\n",
      "bl_qa_orig      0.842  0.840  0.765   0.063     0.798    0.795      0.725        0.033\n",
      "bl_qa_plus      0.832  0.831  0.781   0.052     0.799    0.792      0.731        0.033\n",
      "bl_qa_dict      0.856  0.856  0.821   0.048     0.809    0.801      0.741        0.031\n",
      "bl_qa_phrase    0.855  0.854  0.816   0.049     0.800    0.794      0.735        0.030\n",
      "bl_qa_reord     0.862  0.861  0.827   0.048     0.800    0.797      0.738        0.030\n",
      "bl_qa_fasttext  0.851  0.850  0.807   0.048     0.799    0.793      0.734        0.028\n",
      "bl_qa_glove     0.846  0.845  0.807   0.047     0.801    0.794      0.736        0.027\n",
      "bl_qa_ppdb      0.850  0.849  0.807   0.045     0.801    0.797      0.736        0.030\n",
      "bl_qa_wordnet   0.849  0.846  0.809   0.042     0.798    0.794      0.735        0.028\n",
      "\n",
      "                 Acc     F1   F1-Q  F1-STD  UK20-Acc  UK20-F1  UK20-F1-Q  UK20-F1-STD\n",
      "bl_set_ab_lq   0.879  0.877  0.845   0.040     0.806    0.800      0.743        0.026\n",
      "bl_set_ab_hq   0.885  0.885  0.854   0.036     0.809    0.803      0.747        0.032\n",
      "bl_set_all_lq  0.904  0.904  0.879   0.037     0.811    0.805      0.749        0.027\n",
      "bl_set_all_hq  0.924  0.923  0.904   0.032     0.817    0.810      0.755        0.031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('expand_frame_repr', False)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "for r_type in proc_res_df:\n",
    "    pp.pprint(proc_res_df[r_type])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
